{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T10:13:31.579137Z",
     "iopub.status.busy": "2025-04-20T10:13:31.578883Z",
     "iopub.status.idle": "2025-04-20T10:13:38.196967Z",
     "shell.execute_reply": "2025-04-20T10:13:38.196145Z",
     "shell.execute_reply.started": "2025-04-20T10:13:31.579104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install coala-fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T10:13:40.639589Z",
     "iopub.status.busy": "2025-04-20T10:13:40.639287Z",
     "iopub.status.idle": "2025-04-20T10:13:40.759375Z",
     "shell.execute_reply": "2025-04-20T10:13:40.758316Z",
     "shell.execute_reply.started": "2025-04-20T10:13:40.639561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/SonyResearch/COALA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T07:49:27.801346Z",
     "iopub.status.busy": "2025-06-09T07:49:27.801119Z",
     "iopub.status.idle": "2025-06-09T07:49:27.947140Z",
     "shell.execute_reply": "2025-06-09T07:49:27.946147Z",
     "shell.execute_reply.started": "2025-06-09T07:49:27.801326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/trduy9/COALA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/working/COALA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile coala_cifar10_resnet18.py\n",
    "\n",
    "\n",
    "import coala  \n",
    "import argparse  \n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "from torchvision.models import resnet18, ResNet18_Weights  \n",
    "from coala.models import BaseModel  \n",
    "\n",
    "# Parse command line arguments  \n",
    "parser = argparse.ArgumentParser(description='COALA CIFAR10 with Pretrained ResNet18 example')  \n",
    "parser.add_argument('--num_clients', type=int, default=50, help='Number of clients')  \n",
    "parser.add_argument('--participant_rate', type=float, default=0.1, help='Participant rate')  \n",
    "parser.add_argument('--rounds', type=int, default=200, help='Number of rounds')  \n",
    "parser.add_argument('--batch_size', type=int, default=64, help='Batch size')  \n",
    "parser.add_argument('--epochs', type=int, default=5, help='Local epochs')  \n",
    "parser.add_argument('--alpha', type=float, default=0.5, help='Alpha for Dirichlet distribution')  \n",
    "parser.add_argument('--gpu', type=int, default=0, help='GPU to use (0 for CPU)')  \n",
    "args = parser.parse_args()\n",
    "\n",
    "# Device setup with GPU availability check\n",
    "available_gpu_count = torch.cuda.device_count()\n",
    "if available_gpu_count > 0 and args.gpu < available_gpu_count:\n",
    "    device = torch.device(f\"cuda:{args.gpu}\")\n",
    "    selected_gpu = args.gpu\n",
    "else:\n",
    "    print(f\"[WARNING] Requested GPU {args.gpu} is not available. Switching to CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    selected_gpu = 0\n",
    "\n",
    "# Calculate clients per round from participant rate  \n",
    "clients_per_round = max(1, int(args.num_clients * args.participant_rate))  \n",
    "\n",
    "# Define a custom ResNet18 model that inherits from COALA's BaseModel  \n",
    "class PretrainedResNet18(BaseModel):  \n",
    "    def __init__(self, num_classes=10):  \n",
    "        super(PretrainedResNet18, self).__init__()  \n",
    "        # Load a pretrained ResNet18 model with weights from ImageNet  \n",
    "        self.model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)  \n",
    "\n",
    "        # Replace the final fully connected layer to match CIFAR10 classes (10)  \n",
    "        in_features = self.model.fc.in_features  \n",
    "        self.model.fc = nn.Linear(in_features, num_classes)  \n",
    "\n",
    "    def forward(self, x):  \n",
    "        return self.model(x)  \n",
    "\n",
    "# Register our custom model with COALA  \n",
    "coala.register_model(PretrainedResNet18(num_classes=10))  \n",
    "\n",
    "# Define COALA configuration  \n",
    "config = {  \n",
    "    \"data\": {  \n",
    "        \"dataset\": \"cifar10\",  \n",
    "        \"num_of_clients\": args.num_clients,  \n",
    "        #\"split_type\": \"dir\",  \n",
    "        \"alpha\": args.alpha,  \n",
    "        \"min_size\": 10  \n",
    "    },  \n",
    "    \"server\": {  \n",
    "        \"rounds\": args.rounds,  \n",
    "        \"clients_per_round\": clients_per_round,  \n",
    "        \"test_every\": 1,  \n",
    "        \"aggregation_strategy\": \"FedAvg\"  \n",
    "    },  \n",
    "    \"client\": {  \n",
    "        \"batch_size\": args.batch_size,  \n",
    "        \"test_batch_size\": 32,\n",
    "        \"local_epoch\": args.epochs,  \n",
    "        \"optimizer\": {  \n",
    "            \"type\": \"SGD\",  \n",
    "            \"lr\": 0.01,  \n",
    "            \"momentum\": 0.9,  \n",
    "            \"weight_decay\": 0.0005 \n",
    "        }  \n",
    "    },  \n",
    "    \"test_mode\": \"test_in_server\",  \n",
    "    \"gpu\": selected_gpu  \n",
    "}  \n",
    "\n",
    "# Initialize COALA with our configuration  \n",
    "coala.init(config)  \n",
    "\n",
    "# Run federated learning  \n",
    "coala.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python coala_cifar10_resnet18.py --num_clients 100 --participant_rate 0.1 --rounds 50 --batch_size 32 --epochs 5 --gpu 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T09:11:01.578072Z",
     "iopub.status.busy": "2025-06-09T09:11:01.577757Z",
     "iopub.status.idle": "2025-06-09T09:11:08.301129Z",
     "shell.execute_reply": "2025-06-09T09:11:08.299930Z",
     "shell.execute_reply.started": "2025-06-09T09:11:01.578042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Transform\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "    \n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "#                          (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Load CIFAR-10 (ví dụ)\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "#                                         download=True, transform=transform_train)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# # Unnormalize để hiển thị\n",
    "# def imshow(img):\n",
    "#     mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "#     std = np.array([0.2023, 0.1994, 0.2010])\n",
    "    \n",
    "#     img = img.numpy().transpose((1, 2, 0))  # C,H,W -> H,W,C\n",
    "#     img = std * img + mean  # unnormalize\n",
    "#     img = np.clip(img, 0, 1)  # giới hạn giá trị để hiển thị đúng\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# # Lấy 1 batch ảnh\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = next(dataiter)\n",
    "\n",
    "# # Hiển thị từng ảnh\n",
    "# for i in range(images.size(0)):\n",
    "#     imshow(images[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import coala\n",
    "\n",
    "# # Define customized configurations.\n",
    "# config = {\n",
    "#     \"data\": {\n",
    "#         \"dataset\": \"cifar10\", \n",
    "#         \"num_of_clients\": 50\n",
    "#     },\n",
    "#     \"server\": {\n",
    "#         \"rounds\": 50, \n",
    "#         \"clients_per_round\": 5,\n",
    "#         \"save_model_every\": 5,\n",
    "#         \"batch_size\": 32\n",
    "#     },\n",
    "#     \"client\": {\n",
    "#         \"local_epoch\": 5,\n",
    "#         \"batch_size\": 64,\n",
    "#         \"test_batch_size\": 32\n",
    "#     },\n",
    "#     \"model\": \"resnet18\",\n",
    "#     \"test_mode\": \"test_in_server\",\n",
    "# }\n",
    "# # Initialize COALA with the new config.\n",
    "# coala.init(config)\n",
    "# # Execute federated learning training.\n",
    "# coala.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-10T07:08:28.652775Z",
     "iopub.status.busy": "2025-03-10T07:08:28.652489Z",
     "iopub.status.idle": "2025-03-10T07:08:31.917490Z",
     "shell.execute_reply": "2025-03-10T07:08:31.916443Z",
     "shell.execute_reply.started": "2025-03-10T07:08:28.652750Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-03-14T08:17:01.550436Z",
     "iopub.status.busy": "2025-03-14T08:17:01.550098Z",
     "iopub.status.idle": "2025-03-14T08:22:42.268311Z",
     "shell.execute_reply": "2025-03-14T08:22:42.267666Z",
     "shell.execute_reply.started": "2025-03-14T08:17:01.550412Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# import wandb\n",
    "# wandb.login(key=\"808980872685635e4a739ff7386255d41ec8f8f1\")\n",
    "\n",
    "# # Start a new wandb run to track this script.\n",
    "# run = wandb.init(\n",
    "#     # Set the wandb entity where your project will be logged (generally your team name).\n",
    "#     entity=\"vptduy\",\n",
    "#     # Set the wandb project where this run will be logged.\n",
    "#     project=\"test\"\n",
    "#     # Track hyperparameters and run metadata.\n",
    "\n",
    "# )\n",
    "\n",
    "# # Simulate training.\n",
    "# epochs = 5\n",
    "# offset = random.random() / 5\n",
    "# for epoch in range(2, epochs):\n",
    "#     acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
    "#     loss = 2**-epoch + random.random() / epoch + offset\n",
    "\n",
    "#     # Log metrics to wandb.\n",
    "#     run.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# # Finish the run and upload any remaining data.\n",
    "# run.finish()\n",
    "\n",
    "# # Define part of customized configs.\n",
    "# config = {\n",
    "#     \"data\": {\n",
    "#         \"dataset\": \"cifar10\", \n",
    "#         \"num_of_clients\": 1000\n",
    "#     },\n",
    "#     \"server\": {\n",
    "#         \"rounds\": 5, \n",
    "#         \"clients_per_round\": 2\n",
    "#     },\n",
    "#     \"client\": {\"local_epoch\": 5},\n",
    "#     \"model\": \"resnet18\",\n",
    "#     \"test_mode\": \"test_in_server\",\n",
    "# }\n",
    "\n",
    "# # Initialize COALA with the new config.\n",
    "# coala.init(config)\n",
    "# # Execute federated learning training.\n",
    "# coala.run()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6867610,
     "sourceId": 11027787,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
